
111
**脏读**
如果一个事务读取到了另一个未提交事务修改过的数据，我们就称发生了脏读现象。

**不可重复读**
同一个事务内，前后多次读取，读取到的数据内容不一致。侧重点在两次读取的同一条数据的结果不一致。

**幻读**
如果一个事务先根据某些搜索条件查询出一些记录，在该事务未提交时，另一个事务写入了一些符合那些搜索条件的记录（如insert、delete、update），就意味着发生了**幻读**。侧重点在发生了数据的增减。



####  四大隔离级别

为了解决并发事务存在的**脏读、不可重复读、幻读**等问题，数据库大叔设计了四种隔离级别。分别是**读未提交，读已提交，可重复读，串行化（Serializable）**。
1. 读未提交。读未提交隔离级别，只限制了两个数据**不能同时修改**，但是修改数据的时候，即使事务**未提交**，都是可以被别的事务读取到的，这级别的事务隔离有**脏读、重复读、幻读**的问题；

2. 读已提交。读已提交隔离级别，当前事务只能读取到其他事务**提交**的数据，所以这种事务的隔离级别**解决了脏读**问题，但还是会存在**重复读、幻读**问题；

3. 可重复读。可重复读隔离级别，限制了读取数据的时候，不可以进行修改，所以**解决了重复读**的问题，但是读取范围数据的时候，是可以插入数据，所以还会存在**幻读**问题；

4. 串行化。事务最高的隔离级别，在该级别下，所有事务都是进行**串行化顺序**执行的。可以避免脏读、不可重复读与幻读所有并发问题。但是这种事务隔离级别下，事务执行很耗性能。

InnoDB默认的隔离级别是RR，需要注意的是，在SQL标准中，RR是无法避免幻读问题的，但是InnoDB实现的RR避免了幻读问题。

#### MVCC
**什么是 MVCC？**
MVCC，即**Multi-Version Concurrency Control （多版本并发控制）**。它是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。

> 通俗的讲，数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，在某个事务对其进行操作的时候，需要查看这一条记录的隐藏列事务版本id，比对事务id并根据事物隔离级别去判断读取哪个版本的数据。


数据库隔离级别读**已提交、可重复读** 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。

 **关键知识点**
1. 事务版本号。
   事务每次开启前，都会从数据库获得一个**自增**长的事务ID，可以从事务ID判断事务的执行先后顺序。这就是事务版本号。
2. 隐式字段.
   对于InnoDB存储引擎，每一行记录都有两个隐藏列**trx_id**、**roll_pointer**，如果表中没有主键和非NULL唯一键时，则还会有第三个隐藏的主键列**row_id**。
3. undo log.
   **回滚日志**，用于记录数据被修改前的信息。在表记录修改之前，会先把数据拷贝到undo log里，如果事务回滚，即可以通过undo log来还原数据。
	可以这样认为，当delete一条记录时，undo log 中会记录一条对应的insert记录，当update一条记录时，它记录一条对应相反的update记录。

undo log有什么**用途**呢？

1. 事务回滚时，保证原子性和一致性。
2. 用于MVCC**快照读**。

**版本链**
多个事务并行操作某一行数据时，不同事务对该行数据的修改会产生多个版本，然后通过回滚指针（roll_pointer），连成一个链表，这个链表就称为**版本链**。如下：

![[Pasted image 20230812143410.png]]

**快照读和当前读**
**快照读：** 读取的是记录数据的可见版本（有旧的版本）。不加锁,普通的select语句都是快照读,如：
`select * from core_user where id > 2;`

**当前读**：读取的是记录数据的最新版本，显式加锁的都是当前读
`select * from core_user where id > 2 for update;
`select * from account where id>2 lock in share mode;

**Read View**

- **Read View是什么呢？** 它就是事务执行SQL语句时，产生的读视图。实际上在innodb中，每个SQL语句执行前都会得到一个Read View。
- **Read View有什么用呢？** 它主要是用来做可见性判断的，即判断当前事务可见哪个版本的数据~

Read View是如何保证可见性判断的呢？我们先看看Read view 的几个重要属性

- m_ids:当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。
- min_limit_id:表示在生成ReadView时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。
- max_limit_id:表示生成ReadView时，系统中应该分配给下一个事务的id值。
- creator_trx_id: 创建当前read view的事务ID

**Read view 匹配条件规则**如下：

1. 如果数据事务ID `trx_id < min_limit_id`，表明生成该版本的事务在生成Read View前，已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。
2. 如果`trx_id>= max_limit_id`，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。
3. 如果 `min_limit_id =<trx_id< max_limit_id`,需腰分3种情况讨论

> - （1）.如果`m_ids`包含`trx_id`,则代表Read View生成时刻，这个事务还未提交，但是如果数据的`trx_id`等于`creator_trx_id`的话，表明数据是自己生成的，因此是**可见**的。
> - （2）如果`m_ids`包含`trx_id`，并且`trx_id`不等于`creator_trx_id`，则Read View生成时，事务未提交，并且不是自己生产的，所以当前事务也是**看不见**的；
> - （3）.如果`m_ids`不包含`trx_id`，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。


**Read view工作方式**
- 在读已提交（RC）隔离级别下，同一个事务里面，**每一次查询都会产生一个新的Read View副本**，可能发生在两次生成read view期间别的事务提交。这样就可能造成同一个事务里前后读取数据可能不一致的问题（不可重复读并发问题）。
-  在可重复读（RR）隔离级别下，**一个事务里只会获取一次read view**，都是副本共用的，从而保证每次查询的数据都是一样的。在 REPEATABLE READ 隔离级别下，事务 A 第一次执行普通的 SELECT 语句时生成了一个 **ReadView**（且在 RR 下只会生成一个 RV），之后事务 B 向 user 表中新插入一条记录并提交。

ReadView 并不能阻止事务 A 执行 UPDATE 或者 DELETE 语句来改动这个新插入的记录（由于事务 B 已经提交，因此改动该记录并不会造成阻塞），但是这样一来，这条新记录的 `trx_id` 隐藏列的值就变成了事务 A 的事务 id。之后 A 再使用普通的 SELECT 语句去查询这条记录时就可以看到这条记录了，也就可以把这条记录返回给客户端。

因为这个特殊现象的存在，我们也可以认为 **MVCC 并不能完全禁止幻读**。

  
#### 如何解决幻读

在**第 2 点**中，我们知道数据库的读操作分为**当前读**和**快照读**，而在 RR 隔离级别下，**MVCC 解决了在快照读的情况下的幻读**，而在实际场景中，我们可能需要读取实时的数据，比如在银行业务等特殊场景下，必须是需要读取到实时的数据，此时就不能快照读。

那么有什么方法来解决这个问题呢？

毫无疑问，在并发场景下，我们可以通过加锁的方式来实现当前读，而在 MySQL 中则是通过`Next-Key Locks`来解决幻读的问题。（关于 MySQL 中的锁的介绍可以看看这篇文章：[一文了解 MySQL 中的锁](https://link.juejin.cn?target=https%3A%2F%2Fjavatv.blog.csdn.net%2Farticle%2Fdetails%2F121940259 "https://javatv.blog.csdn.net/article/details/121940259")）。

`Next-Key Locks`包含两部分：记录锁（行锁，Record Lock），间隙锁（Gap Locks）。**记录锁是加在索引上的锁，间隙锁是加在索引之间的**。

#### 6.1 Record Lock

**记录锁，单条索引记录上加锁**。

Record Lock 锁住的永远是索引，不包括记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。

记录锁是有 S 锁和 X 锁之分的，当一个事务获取了一条记录的 S 型记录锁后，其他事务也可以继续获取该记录的 S 型记录锁，但不可以继续获取 X 型记录锁；当一个事务获取了一条记录的 X 型记录锁后，其他事务既不可以继续获取该记录的 S 型记录锁，也不可以继续获取 X 型记录锁。

#### 6.2 Gap Locks

间隙锁，对索引前后的间隙上锁，不对索引本身上锁。前开后开区间。

MySQL 在 REPEATABLE READ 隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用 MVCC 方案解决，也可以采用加锁方案解决。但是在使用加锁方案解决时有问题，就是事务在第一次执行读取操作时，那些幻影记录尚 不存在，我们无法给这些幻影记录加上记录锁。所以我们可以使用间隙锁对其上锁。

如存在这样一张表：



```sql
CREATE TABLE test  
(  
    id     INT(1) NOT NULL AUTO_INCREMENT,  
    number INT(1) NOT NULL COMMENT '数字',  
    PRIMARY KEY (id),  
    KEY number (number) USING BTREE  
) ENGINE = INNODB  
  AUTO_INCREMENT = 1  
  DEFAULT CHARSET = utf8;
```

如下：

开启一个事务 A：


`BEGIN; ​ SELECT * FROM test WHERE number = 3 FOR UPDATE;`

此时，会对`((1,1),(5,3))`和`((5,3),(7,8))`之间上锁。

![image-20211214115101096](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/34cec90c42ad4b92ae3dfaa027d1b320~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

如果此时在开启一个事务 B 进行插入数据，如下：

sql

复制代码

`BEGIN; ​ # 阻塞 INSERT INTO test (id, number) VALUES (2,2);` 

结果如下：

![image-20211214151211227](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/45c54ac5b0df4132a2914db77abbf25f~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

为什么不能插入？因为记录`(2,2)`要 插入的话，在索引 `number`上，刚好落在`((1,1),(5,3))`和`((5,3),(7,8))`之间，是有锁的，所以不允许插入。 如果在范围外，当然是可以插入的，如：


`INSERT INTO test (id, number) VALUES (8,8);` 

另外，既然涉及到索引，那么**索引对间隙锁会产生什么影响**？

1. 对主键或唯一索引，如果当前读时，where 条件全部精确命中(=或in)，这种场景本身就不会出现幻读，所以只会加行记录锁，也就是说**间隙锁会退化为行锁**（记录锁）。
2. 非唯一索引列，如果 where 条件部分命中(>、<、like等)或者全未命中，则会加附近间隙锁。例如，某表数据如下，非唯一索引`2,6,9,9,11,15`。如下语句要操作非唯一索引列 9 的数据，间隙锁将会锁定的列是(6,11]，该区间内无法插入数据。
3. 对于没有索引的列，当前读操作时，会加全表间隙锁，生产环境要注意。

  


  ##### MVCC实现原理分析
 **查询一条记录，基于MVCC，是怎样的流程**
1. 获取事务自己的版本号，即事务ID
2. 获取Read View
3. 查询得到的数据，然后Read View中的事务版本号进行比较。
4. 如果不符合Read View的可见性规则， 即就需要Undo log中历史快照;
5. 最后返回符合规则的数据

InnoDB 实现MVCC，是通过 `Read View+ Undo Log` 实现的，Undo Log 保存了历史快照，Read View可见性规则帮助判断当前版本的数据是否可见。


#### 幻读总结

但是，对于幻读来说，还存在当前读和快照读的情况：

1. RR 隔离级别下间隙锁才有效，**RC 隔离级别下没有间隙锁**；
2. RR 隔离级别下为了解决幻读问题：**快照读依靠MVCC控制，当前读通过间隙锁解决**；
3. 间隙锁和行锁合称 Next-Key Locks，每个 Next-Key Locks 是前开后闭区间；
4. 间隙锁的引入，可能会导致同样语句锁住更大的范围，影响并发度。

  



#### 数据库设计
##### 1、什么是三大范式？
第一范式（1NF）：字段（或属性）是不可分割的最小单元，即不会有重复的列，体现原子性

第二范式（2NF）：满足 1NF 前提下，存在一个候选码，非主属性全部依赖该候选码，即存在主键，体现唯一性，专业术语则是消除部分函数依赖

第三范式（3NF）：满足 2NF 前提下，非主属性必须互不依赖，消除传递依赖
  
#### 索引
首先了解一下什么是索引，索引是对数据库表中一列或多列的值进行排序的数据结构，用于快速访问数据库表中的特定信息。

##### 索引的几种类型或分类？
1）从物理结构上可以分为聚集索引和非聚集索引两类：

- 聚簇索引指索引的键值的逻辑顺序与表中相应行的物理顺序一致，即每张表只能有一个聚簇索引，也就是我们常说的主键索引；
- 非聚簇索引的逻辑顺序则与数据行的物理顺序不一致。

从应用上可以划分为一下几类：

1. 普通索引：MySQL 中的基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了提高查询效率。通过 ALTER TABLE table_name ADD INDEX index_name (column) 创建；

2. 唯一索引：索引列中的值必须是唯一的，但是允许为空值。通过 ALTER TABLE table_name ADD UNIQUE index_name (column) 创建；

3. 主键索引：特殊的唯一索引，也成聚簇索引，不允许有空值，并由数据库帮我们自动创建；

4. 组合索引：组合表中多个字段创建的索引，遵守最左前缀匹配规则；

5. 全文索引：只有在 MyISAM 引擎上才能使用，同时只支持 CHAR、VARCHAR、TEXT 类型字段上使用。


#### 为什么选b+树？
相比b数和二叉搜索树这些数，它们的键和值是放在同样的节点中的，这导致一个内存页中能存放的索引数量就少了，间接导致需要更多次IO才能找到对应数据，性能差。而且二叉搜索树在插入和删除时为了保持树高的平衡需要多次旋转操作，又会带来许多IO，性能差。

而b+数的值全部存放在叶子节点，只需要更少次数IO就可以查到数据。

b树查找时间复杂度从O（1）到O（n）不等，而b+树查找时间复杂度固定为O（n），更稳定。且b+树的叶子节点之间存在连接的指针，利于遍历和范围查找。


#### 什么是最左匹配原则？
顾名思义，最左优先，以最左边为起点任何连续的索引都能匹配上。同时遇到范围查询（>、<、between、like）就会停止匹配。

如建立 (a,b,c,d) 索引，查询条件 b = 2 是匹配不到索引的，但是如果查询条件是 a = 1 and b = 2 或 a=1 又或 b = 2 and a = 1 就可以，因为优化器会自动调整 a,b 的顺序。

再比如 a = 1 and b = 2 and c > 3 and d = 4，其中 d 是用不到索引的，因为 c 是一个范围查询，它之后的字段会停止匹配。

原理：在b+树中连续索引的有序性是从左到右的，即索引为(abcd)的情况下，优先a排序，a相等的情况下才是b排序，以此类推。


#### 什么是覆盖索引。
在MySQL中，覆盖索引（Covering Index）是一种索引结构，它包含了查询所需的所有数据列，可以满足查询的需求而无需回表到原始数据行。

通常情况下，当执行一个查询语句时，MySQL需要根据索引定位到匹配的记录，并从磁盘读取相应的数据行。如果查询语句需要返回的数据列包含在索引中，这个索引就是一个覆盖索引。

使用覆盖索引可以带来以下好处：

1. 减少磁盘IO：由于覆盖索引包含了查询所需的所有数据，不需要回表到原始数据行，减少了磁盘IO操作，从而提高查询的性能。
    
2. 减少CPU开销：回表操作需要在内存中进行额外的查找和比较操作，而覆盖索引可以减少这些操作，减少了CPU的开销。
    
3. 减少网络传输：当MySQL作为分布式数据库时，返回较小的结果集可以减少网络传输的开销，提高查询的效率。

#### 什么是索引下推？
索引下推（Index condition pushdown） 简称 ICP，在 Mysql 5.6 版本上推出的一项用于优化查询的技术。

在不使用索引下推的情况下，在使用非主键索引进行查询时，存储引擎通过索引检索到数据，然后返回给 MySQL 服务器，服务器判断数据是否符合条件。

而有了索引下推之后，如果存在某些被索引列的判断条件时，MySQL 服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合 MySQL 服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给 MySQL 服务器。

索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少 MySQL 服务器从存储引擎接收数据的次数。

#### InnoDB 为何推荐使用自增主键？

自增 ID 可以保证每次插入时 B+ 树索引是从右边扩展的，因此相比自定义 ID （如 UUID）可以避免 B+ 树的频繁合并和分裂。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。


#### 什么是double write
doublewrite缓冲区是位于系统表空间中的存储区域，在该区域中，InnoDB会在将页面写入数据文件中的适当位置之前，从InnoDB缓冲池中刷新这些页面。仅在刷新页面并将其写入doublewrite缓冲区后，InnoDB才会将页面写入其适当位置。如果在页面写入过程中发生操作系统，存储子系统或mysqld进程崩溃，InnoDB稍后可以在崩溃恢复期间从doublewrite缓冲区中找到该页面的良好副本。

#### 原子性 undo log
undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。

#### 持久性redo log 

mysql的内存页大小为16kb，如果在写到一半出现了宕机或崩溃，数据会无法恢复。所以引入redo log来保证持久性。


在写入数据时，MySQL通常会先将数据写入重做日志（redo log）中，然后再将数据写入缓冲池（buffer pool）。

这个过程被称为“写前日志（write-ahead logging）”策略，它是数据库管理系统保障事务的持久性和一致性的重要机制之一。下面是写前日志策略的基本流程：

1. **写入重做日志：** 当事务执行写操作（如插入、更新、删除）时，MySQL首先将对数据的修改操作记录到重做日志中，而不是立即将修改应用到实际数据页。
    
2. **返回事务成功：** 一旦重做日志记录成功写入，MySQL会通知应用程序事务已经成功。这使得应用程序可以继续执行下一步操作，而不需要等待实际数据写入磁盘。
    
3. **延迟写入数据页：** 实际数据页的更新可能会被延迟写入磁盘。这是因为重做日志已经保证了在崩溃或故障发生时可以重新应用事务的更改，因此实际的数据写入可以根据系统的负载和优化策略来调度，以提高性能。
    
4. **刷新到磁盘：** 在适当的时机，MySQL将缓冲池中的数据页刷新到磁盘，从而实现数据的持久性。这个过程可以由数据库引擎根据不同的策略来触发，例如脏页（被修改但尚未写入磁盘的页）数量的阈值。
    

通过这种写前日志的策略，数据库可以在事务提交后迅速返回成功，并将实际的数据写入磁盘的操作延迟到更合适的时间，从而提高了事务的吞吐量和性能。重做日志在这个过程中起到了关键的作用，确保了在崩溃等情况下数据的一致性和恢复能力。

重做日志的写入会对性能产生一定的影响，因为每个事务都需要先写入重做日志，然后才能返回成功。然而，这种写前日志（write-ahead logging）策略是为了确保数据的持久性和一致性而采取的重要机制，它提供了关键的数据库恢复能力。

尽管写入重做日志会增加每个事务的开销，但是这种策略可以带来一些优势：

1. **更快的返回时间：** 在写入重做日志后，数据库可以迅速返回事务成功，因为重做日志已经保证了事务的持久性。这使得应用程序能够更快速地继续执行下一步操作，而不需要等待实际数据写入磁盘。
    
2. **减少随机磁盘写入：** 重做日志通常会被写入连续的磁盘区域，而不是随机分布在数据文件中。这可以减少随机写入操作，从而提高磁盘的性能。
    
3. **支持事务恢复：** 重做日志是数据库恢复的关键，可以在崩溃或故障发生时重新应用事务的修改，从而保障数据的一致性


#### redo log与binlog
我们知道，在MySQL中还存在binlog(二进制日志)也可以记录写操作并用于数据的恢复，但二者是有着根本的不同的：

（1）作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。

（2）层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层(可以参考文章前面对MySQL逻辑架构的介绍)实现的，同时支持InnoDB和其他存储引擎。

（3）内容不同：redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。

（4）写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元：





#### 隔离性

隔离性追求的是并发情形下事务之间互不干扰。简单起见，我们主要考虑最简单的读操作和写操作(加锁读等特殊读操作会特殊说明)，那么隔离性的探讨，主要可以分为两个方面：

- (一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性
- (一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性


#### 一致性

基本概念

一致性是指事务执行结束后，**数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。**数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。

实现

可以说，一致性是事务追求的最终目标：前面提到的原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。

实现一致性的措施包括：

- 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证
- 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等
- 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致

#### 锁
1、数据库锁的作用以及有哪些锁？
当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。即锁的作用是解决并发问题。

从锁的粒度划分，可以将锁分为表锁、行锁以及页锁。

行级锁：是锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。
行级锁开销大，加锁慢，且会出现死锁。但锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

表级锁：是粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。

页级锁：是粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折中的页级，一次锁定相邻的一组记录。

开销和加锁时间界于表锁和行锁之间，会出现死锁。锁定粒度界于表锁和行锁之间，并发度一般。

####  MySQL 索引使用有哪些注意事项呢？
可以从两个维度回答这个问题：索引哪些情况会失效，索引不适合哪些场景

**索引哪些情况会失效**
查询条件包含or，会导致索引失效。
隐式类型转换，会导致索引失效，例如age字段类型是int，我们where age = “1”，这样就会触发隐式类型转换。
like通配符会导致索引失效。注意："ABC%“会走range索引，”%ABC"索引才会失效。
联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。
对索引字段进行函数运算。
对索引列运算（如，+、-、*、/），索引失效。
索引字段上使用（!= 或者 < >，not in）时，会导致索引失效。
索引字段上使用is null， is not null，可能导致索引失效。
相join的两个表的字符编码不同，不能命中索引，会导致笛卡尔积的循环计算
mysql估计使用全表扫描要比使用索引快,则不使用索引。

**索引不适合哪些场景**
数据量少的不适合加索引
更新比较频繁的也不适合加索引
离散性低的字段不适合加索引（如性别）


#### 意向锁

意向锁之间的兼容互斥性：

  

![](https://pic4.zhimg.com/80/v2-12e0ee9c0ab14601f7d3ca56d5cdbde7_1440w.webp)

  

即**意向锁之间是互相兼容的**，emmm......那你存在的意义是啥？

虽然意向锁和自家兄弟互相兼容，但是它会与普通的**排他 / 共享锁**互斥：

  

  

![](https://pic1.zhimg.com/80/v2-e02840d766802dc67c4a90215a24b4a8_1440w.webp)

  

  

**注意：这里的排他 / 共享锁指的都是表锁！！！意向锁不会与行级的共享 / 排他锁互斥！！！**

现在我们回到刚才 users 表的例子：

事务 A 获取了某一行的排他锁，并未提交：

```text
SELECT * FROM users WHERE id = 6 FOR UPDATE;
```

此时 users 表存在两把锁：users 表上的**意向排他锁**与 id 为 6 的数据行上的**排他锁**。

事务 B 想要获取 users 表的共享锁：

```text
LOCK TABLES users READ;
```

此时事务 B 检测事务 A 持有 users 表的**意向排他锁**，就可以得知事务 A 必然持有该表中某些数据行的**排他锁**，那么事务 B 对 users 表的加锁请求就会被排斥（阻塞），而无需去检测表中的每一行数据是否存在排他锁。
#### MySQL 遇到过死锁问题吗，你是如何解决的？


可能出现死锁的场景：
1. 两个并发线程互相先锁住了两个资源然后交叉申请对方已经占有的资源。

排查死锁的步骤：

- 查看死锁日志show engine innodb status;
- 找出死锁Sql
- 分析sql加锁情况
- 模拟死锁案发
- 分析死锁日志
- 分析死锁结果


#### 分库分表
主从复制：副本库负责读，主库负责写。主从同步保持数据一致。

二、分库分表

水平分库

![](https://pic3.zhimg.com/80/v2-c6de98fbf6dd9cd1cef6ced803294f8e_1440w.webp)

1. 概念：以**字段**为依据，按照一定策略（hash、range等），将一个**库**中的数据拆分到多个**库**中。
2. 结果：

- 每个**库**的**结构**都一样；
- 每个**库**的**数据**都不一样，没有交集；
- 所有**库**的**并集**是全量数据；

- 场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。
- 分析：库多了，io和cpu的压力自然可以成倍缓解。

水平分表

![](https://pic4.zhimg.com/80/v2-5a5447ec26f1391c00fcb1c97e416433_1440w.webp)

1. 概念：以**字段**为依据，按照一定策略（hash、range等），将一个**表**中的数据拆分到多个**表**中。
2. 结果：

- 每个**表**的**结构**都一样；
- 每个**表**的**数据**都不一样，没有交集；
- 所有**表**的**并集**是全量数据；

- 场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。
- 分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。

垂直分库

![](https://pic2.zhimg.com/80/v2-6484e798eeb54df53020af70c4d6645d_1440w.webp)

1. 概念：以**表**为依据，按照业务归属不同，将不同的**表**拆分到不同的**库**中。
2. 结果：

- 每个**库**的**结构**都不一样；
- 每个**库**的**数据**也不一样，没有交集；
- 所有**库**的**并集**是全量数据；

- 场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。
- 分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。

垂直分表

![](https://pic4.zhimg.com/80/v2-cd623744d880d155a6c513079e52b7af_1440w.webp)

1. 概念：以**字段**为依据，按照字段的活跃性，将**表**中字段拆到不同的**表**（主表和扩展表）中。
2. 结果：

- 每个**表**的**结构**都不一样；
- 每个**表**的**数据**也不一样，一般来说，每个表的**字段**至少有一列交集，一般是主键，用于关联数据；
- 所有**表**的**并集**是全量数据；

- 场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。
- 分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据

#### 什么是一致性哈希
一、使用简单的哈希函数

`m = hash(o) mod n`

- 其中，o为对象名称，n为机器的数量，m为机器编号。

考虑以下例子：

3个机器节点，10个数据 的哈希值分别为1,2,3,4,…,10。使用的哈希函数为：(`m=hash(o) mod 3`)  
机器0 上保存的数据有：3，6，9  
机器1 上保存的数据有：1，4，7，10  
机器2 上保存的数据有：2，5，8

当增加一台机器后，此时n = 4，各个机器上存储的数据分别为：

```text
机器0 上保存的数据有：4，8
机器1 上保存的数据有：1，5，9
机器2 上保存的数据有：2，6，10
机器3 上保存的数据有：3，7
```

只有数据1和数据2没有移动，所以当集群中数据量很大时，采用一般的哈希函数，在节点数量动态变化的情况下会造成大量的数据迁移，导致网络通信压力的剧增，严重情况，还可能导致数据库宕机。

`原因：原本3%3=0,添加完节点后3%4=3，即现在通过取模找不到原来的数据了`

#### 一致性哈希算法

> 一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n 个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。

简单的说，一致性哈希是将整个哈希值空间组织成一个虚拟的圆环，如假设哈希函数H的值空间为0-2^32-1（哈希值是32位无符号整形），整个哈希空间环如下：

![哈希环](https://image.talkmoney.cn/2018-12-27/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545916990776.png) 整个空间按顺时针方向组织，0和2^32-1在零点中方向重合。

接下来，把服务器按照IP或主机名作为关键字进行哈希，这样就能确定其在哈希环的位置。 ![哈希环2](https://image.talkmoney.cn/2018-12-27/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545917087577.png) 然后，我们就可以使用哈希函数H计算值为key的数据在哈希环的具体位置h，根据h确定在环中的具体位置，从此位置沿顺时针滚动，遇到的第一台服务器就是其应该定位到的服务器。

例如我们有A、B、C、D四个数据对象，经过哈希计算后，在环空间上的位置如下：

![哈希环3](https://image.talkmoney.cn/2018-12-27/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545917163991.png) 根据一致性哈希算法，数据A会被定为到Server 1上，数据B被定为到Server 2上，而C、D被定为到Server 3上。

##### 3 容错性和扩展性

那么使用一致性哈希算法的容错性和扩展性如何呢？

##### 3.1 容错性

假如RedisService2宕机了，那么会怎样呢？

![Redis2宕机](https://image.talkmoney.cn/2018-12-28/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545973066323.png)

那么，数据B对应的节点保存到RedisService3中。因此，其中一台宕机后，干扰的只有前面的数据（原数据被保存到顺时针的下一个服务器），而不会干扰到其他的数据。

##### 3.2 扩展性

下面考虑另一种情况，假如增加一台服务器Redis4，具体位置如下图所示：

![RedisServicee4](https://image.talkmoney.cn/2018-12-28/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545973609449.png) 原本数据C是保存到Redis3中，但由于增加了Redis4，数据C被保存到Redis4中。干扰的也只有Redis3而已，其他数据不会受到影响。

因此，一致性哈希算法对于节点的增减都只需重定位换空间的一小部分即可，具有较好的容错性和可扩展性

##### 4 虚拟节点

前面部分都是讲述到Redis节点较多和节点分布较为均衡的情况，如果节点较少就会出现节点分布不均衡造成数据倾斜问题。

例如，我们的的系统有两台Redis，分布的环位置如下图所示：

![哈希环](https://image.talkmoney.cn/2018-12-28/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545977832954.png) 这会产生一种情况，Redis1的hash范围比Redis2的hash范围大，导致数据大部分都存储在Redis1中，数据存储不平衡。

为了解决这种数据存储不平衡的问题，一致性哈希算法引入了**虚拟节点机制**，即对每个节点计算多个哈希值，每个计算结果位置都放置在对应节点中，这些节点**称为虚拟节点**。

具体做法可以在服务器IP或主机名的后面增加编号来实现，例如上面的情况，可以为每个服务节点增加三个虚拟节点，于是可以分为 RedisService1#1、 RedisService1#2、 RedisService1#3、 RedisService2#1、 RedisService2#2、 RedisService2#3，具体位置如下图所示：

![虚拟节点](https://image.talkmoney.cn/2018-12-28/2018-12-27_5%E5%88%86%E9%92%9F%E7%90%86%E8%A7%A3%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/1545978062568.png)

对于数据定位的hash算法仍然不变，只是增加了虚拟节点到实际节点的映射。例如，数据C保存到虚拟节点Redis1#2，实际上数据保存到Redis1中。这样，就能解决服务节点少时数据不平均的问题。在实际应用中，通常将虚拟节点数设置为**32甚至更大**，因此即使**很少的服务节点**也能做到相对**均匀的数据分布**。

  
#### mysql全局唯一自增ID方案

- 数据库自增ID（定义全局表）
- UUID
- Redis的原子递增
- Twitter-Snowflake算法
- 美团的leaf
- MongoDB的ObjectId
- 百度的UidGenerator

1. 数据库自增方案

在数据库中专门创建一张序列表，利用数据库表中的自增ID来为其他业务的数据生成一个全局ID，那么每次要用ID的时候，直接从这个表中获取即可。
`begin;
`REPLACE INTO uid_table (business_id) VALUES (2);
`SELECT LAST_INSERT_ID();
`commit;`

#### UUID

UUID的格式是： xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx 8-4-4-4-12共36个字符，它是一个128bit的二进制转化为16进制的32个字符，然后用4个 - 连接起来的字符串。
**优点:**

本地生成，没有网络消耗，生成简单，没有高可用风险。
**缺点:**

1. 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。
2. 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
3. 无序查询效率低：由于生成的UUID是无序不可读的字符串，所以其查询效率低。
4. UUID不适合用来做数据库的唯一ID，如果用UUID做主键，无序的不递增，大家都知道，主键是有索引的，然后mysql的索引是通过b+树来实现的，每一次新的UUID数据的插入，为了查询的优化，都会对索引底层的b+树进行修改，因为UUID数据是无序的，所以每一次UUID数据的插入都会对主键的b+树进行很大的修改，严重影响性能。


#### 雪花算法
SnowFlake 算法，是 Twitter 开源的分布式 id 生成算法。其核心思想就是：使用一个 64 bit 的 long 型的数字作为全局唯一 id。雪花算法比较常见，在百度的UidGenerator、美团的Leaf中，都有用到雪花算法的实现。

如图6-11所示，表示雪花算法的组成，一共64bit，这64个bit位由四个部分组成。

第一部分， 1bit位，用来表示符号位，而ID一般是正数，所以这个符号位一般情况下是0。
第二部分， 占41 个 bit：表示的是时间戳，是系统时间的毫秒数，但是这个时间戳不是当前系统的时间，而是当前 系统时间-开始时间 ，更大的保证这个ID生成方案的使用的时间！
那么我们为什么需要这个时间戳，目的是为了保证有序性，可读性,我一看我就能猜到ID是什么时候生成的。
41位可以2 41 - 1表示个数字，
如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是：0 至 2 41 -1，减1
是因为可表示的数值范围是从0开始算的，而不是1。
也就是说41位可以表示2 41 -1个毫秒的值，转化成单位年则是(2 41 -1)/1000 * 60 * 60 * 24
*365=69年，也就是能容纳69年的时间

第三部分， 用来记录工作机器id，id包含10bit，意味着这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。
其中这10bit又可以分成2个5bit，前5bit表示机房id、5bit表示机器id，意味着最多支持2^5个机房（32），每个机房可以支持32台机器。
第四部分， 第四部分由12bit组成，它表示一个递增序列，用来记录同毫秒内产生的不同id。
那么我们为什么需要这个序列号，设想下，如果是同一毫秒同一台机器来请求，那么我们怎么保证他的唯一性，这个时候，我们就能用到我们的序列号，

目的是为了保证同一毫秒内同一机器生成的ID是唯一的，这个其实就是为了满足我们ID的这个高
并发，就是保证我同一毫秒进来的并发场景的唯一性。

12位（bit）可以表示的最大正整数是2^12-1=4095，即可以用0、1、2、3、…4094这4095个数字，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号。

12位2进制，如果全部都是1的情况下，那么最终的值就是4095，也就是12bit能够存储的最大的数字是4095.

![[Pasted image 20230815131855.png]]

优点：
毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。
作为DB表的主键，索引效率高。
不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。
高性能高可用：生成时不依赖于数据库，完全在内存中生成。
容量大，每秒中能生成数百万的自增ID。
可以根据自身业务特性分配bit位，非常灵活。
缺点：
强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。
不是严格全局递增的。
原标准实现代码中是直接抛异常，短暂停止对外服务，这样在实际生产中是无法忍受的。




#### 分库分表可能遇到的问题
1. 事务问题：需要用分布式事务啦(应用逻辑解决)
2. 跨节点Join的问题：解决这一问题可以分两次查询实现
3. 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。
4. 数据迁移，容量规划，扩容等问题
5. ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID
6. 跨分片的排序分页问题（后台加大pagesize处理？）


#### 大表limit优化
通过在设计表的时候加上冗余字段，去掉多表链接查询，使用`id`优化提升`limit`性能的例子如下：



`SELECT  a.字段 FROM table a RIGHT JOIN  ( SELECT id  -- 只查id列 FROM table WHERE .....(非聚簇索引的条件查询) LIMIT 1000000,20 ) as b ON b.id = a.id`

原`SQL`是:


`SELECT 需要获取的字段 FROM table WHERE .....(非聚簇索引的条件查询) LIMIT 1000000,20`

由于非聚簇索引的叶子节点上面存储的是主键的`id`，因此，如果`select`只查主键，那么就不需要根据主键`id`再到聚簇索引上面获取记录信息，而如果`select`需要查询除主键外的其它字段信息，就必须要到聚簇索引上面取记录信息。

`limit`是在查询结果基础上跳过多少条记录，也就是说，跳过多少条记录也是需要查询这些记录的信息的。如`limit 10000,20`，那么就需要`10020`次根据主键`id`到聚簇索引上面取记录信息，而`select id`就能减少这`10020`次查询，因为非聚簇索引上面存的就是主键`id`。前提是`where`后面的条件必须确保都是走索引，在全表扫描下，任何优化都是徒劳。

  

#### mysql的主从同步
主从同步的步骤和概念：

- **复制事件（Replication Events）**：主服务器上的数据更改会以复制事件的形式记录在二进制日志中，从服务器通过读取并解析这些事件来执行相应的操作。
    
- **复制线程（Replication Threads）**：从服务器会启动两个重要的复制线程，即 I/O 线程和 SQL 线程。
    
    - **I/O 线程**：从主服务器拉取二进制日志，将数据流复制到从服务器的中继日志（Relay Log）中。
    - **SQL 线程**：从中继日志中读取复制事件，执行这些事件以在从服务器上重现主服务器的更改。
- **复制配置**：在从服务器上，需要配置主服务器的连接信息，包括主服务器的 IP 地址、端口、复制用户等。此外，可以选择是否只读模式、延迟等配置。
    
- **主从同步延迟**：由于网络和服务器负载等原因，从服务器上的数据可能会有一定的延迟，即从服务器的数据不一定与主服务器的数据完全同步。





#### 有一个查询需求，MySQL中有两个表，一个表1000W数据，另一个表只有几千数据，要做一个关联查询，如何优化

对于这种情况，可以考虑以下几种方法来优化关联查询：

1. 确保表上的索引：在关联字段上创建索引可以大大提高查询性能。对于包含1000W数据的表，确保关联字段和查询字段都有适当的索引。
    
2. 使用内连接（INNER JOIN）：内连接只返回两个表中匹配的行，这可以减少结果集的大小。确保查询中使用了正确的连接条件，并使用INNER JOIN语句。
    
3. 限制结果集大小：如果只需要关联查询的前几行结果，可以使用LIMIT关键字来限制结果集的大小。这样可以减少查询的执行时间。
    
4. 使用子查询或临时表：如果在关联查询中使用了大量的条件或复杂的逻辑，可以考虑使用子查询或临时表来提前过滤数据。这可以减少关联查询的数据量。
    
5. 考虑使用缓存：如果查询结果不经常变化，可以考虑使用缓存机制，将查询结果缓存起来，下次查询时直接使用缓存结果，而不需要进行实际的关联查询。
    
6. 数据库分片：如果数据量过大，可以考虑对数据进行分片存储，将数据分散到多个数据库实例中。这样可以减少单个查询操作的数据量。
    
7. 考虑数据库优化工具：可以使用一些数据库优化工具来分析查询性能，并提供相应的优化建议。例如，可以使用MySQL自带的EXPLAIN语句来分析查询执行计划，找出潜在的性能问题。