# Redis

#### 为何使用单线程？

- **官方答案**

因为 Redis 是基于内存的操作，CPU 不会成为 Redis 的瓶颈，而最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了

#### Redis 的数据类型？


1. 字符串（String）：存储单个值。底层实现使用简单动态字符串（Simple Dynamic String）。
    
2. 哈希（Hash）：存储字段和值的映射关系。底层实现使用哈希表（Hash Table）。
    
3. 列表（List）：存储有序的字符串元素列表。底层实现使用双向链表（Doubly Linked List）。
    
4. 集合（Set）：存储无序的唯一字符串元素集合。底层实现使用哈希表或者跳跃表（Skip List）。
    
5. 有序集合（Sorted Set）：类似于集合，但每个元素都关联一个分数（score）。底层实现使用跳跃表和哈希表。
    
6. 地理空间索引（Geospatial Index）：存储地理空间坐标和对象的映射关系。底层实现使用二维的跳跃表。


除了常见的数据结构之外，Redis还提供了一些不太常用但有特定用途的数据结构，包括：

1. Bitmaps（位图）：位图是一种由二进制位组成的数据结构，可以进行高效的位级操作。Redis提供了对位图的操作，例如设置、获取、计数等，适用于处理一些位级信息的场景，如在线状态跟踪、布隆过滤器等。
    
2. HyperLogLog：HyperLogLog 是一种用于估计基数（不重复元素数量）的算法。Redis的 HyperLogLog 数据结构可以用于统计独立元素的数量，而不需要实际存储每个元素，节省了大量内存。
    
3. Streams（流）：流是一种有序、持久化、可扩展的日志数据结构，可以用于实现消息队列、事件驱动等场景。Redis的 Streams 提供了发布-订阅模式下的持久化消息队列功能，支持多个消费者、消费者组等特性。
    
4. GeoHash：GeoHash 是一种用于地理位置编码和检索的算法。Redis的 GeoHash 数据结构支持将地理位置与字符串键关联起来，并可以进行范围查询、距离计算等操作，适用于构建地理位置相关的应用和服务。

#### hyperlog
Redis HyperLogLog 在以下场景中有广泛应用：

1. 基数统计：HyperLogLog 可以用于估计大规模数据集的基数，即不重复元素的数量。它可以在极小的内存占用下提供接近实际基数的估计值，适用于需要快速计算基数的场景，如用户数统计、页面访问数统计等。
    
2. 数据流处理：HyperLogLog 可以用于处理数据流中的重复元素。通过不断添加元素到 HyperLogLog 中，可以实时估计数据流中的不重复元素数量，适用于实时流式数据处理和去重。
    
3. 布隆过滤器：布隆过滤器是一种用于快速判断元素是否存在的数据结构，HyperLogLog 可以被视为布隆过滤器的变种。HyperLogLog 可以用于快速检查一个元素是否属于一个大集合，而不需要存储实际的元素值。
    

HyperLogLog 的底层实现基于概率性算法和位运算。它使用一个固定大小的位数组和一些哈希函数来存储元素信息。具体实现过程包括以下几个步骤：

1. 初始化：创建一个指定大小的位数组，并将所有位初始化为零。
    
2. 添加元素：对于要添加的元素，使用多个哈希函数计算出不同的哈希值，然后根据哈希值将位数组中对应位置的位设置为 1。
    
3. 估计基数：通过统计位数组中值为 1 的位的数量，并应用一定的校正算法，得到基数的估计值。
    

HyperLogLog 的估计算法基于概率统计原理，其中的误差来自于哈希冲突和位计数的统计误差。通过使用更多的位和更多的哈希函数，可以提高估计的准确性，但同时也会增加内存占用和计算开销。

需要注意的是，Redis 的 HyperLogLog 实现是基于 HyperLogLog++ 算法，它在原始的 HyperLogLog 算法基础上进行了改进，提供了更好的估计精度和更小的内存消耗。


#### Redis实现分布式锁
加锁
```java
public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) {  
    String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);  
    if (LOCK_SUCCESS.equals(result)) {  
        return true;  
    }  
    return false;  
}
```

解锁
使用lua脚本首先判断加锁者id和解锁者id是否一致，不一致则return 0,一致的话则return 删除key的结果。
```java
public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) {  
  
    String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";  
    Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));  
    if (RELEASE_SUCCESS.equals(result)) {  
        return true;  
    }  
    return false;  
}
```


#### Redisson实现分布式锁
**加锁的lua脚本**
```lua
-- 若锁不存在：则新增锁，并设置锁重入计数为1、设置锁过期时间
if (redis.call('exists', KEYS[1]) == 0) then
    redis.call('hset', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;
 
-- 若锁存在，且唯一标识也匹配：则表明当前加锁请求为锁重入请求，故锁重入计数+1，并再次设置锁过期时间
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    redis.call('hincrby', KEYS[1], ARGV[2], 1);
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;
 
-- 若锁存在，但唯一标识不匹配：表明锁是被其他线程占用，当前线程无权解他人的锁，直接返回锁剩余过期时间
return redis.call('pttl', KEYS[1]);
```

**解锁Lua脚本**
```lua
-- 若锁不存在：则直接广播解锁消息，并返回1
if (redis.call('exists', KEYS[1]) == 0) then
    redis.call('publish', KEYS[2], ARGV[1]);
    return 1; 
end;
 
-- 若锁存在，但唯一标识不匹配：则表明锁被其他线程占用，当前线程不允许解锁其他线程持有的锁
if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then
    return nil;
end; 
 
-- 若锁存在，且唯一标识匹配：则先将锁重入计数减1
local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); 
if (counter > 0) then 
    -- 锁重入计数减1后还大于0：表明当前线程持有的锁还有重入，不能进行锁删除操作，但可以友好地帮忙设置下过期时期
    redis.call('pexpire', KEYS[1], ARGV[2]); 
    return 0; 
else 
    -- 锁重入计数已为0：间接表明锁已释放了。直接删除掉锁，并广播解锁消息，去唤醒那些争抢过锁但还处于阻塞中的线程
    redis.call('del', KEYS[1]); 
    redis.call('publish', KEYS[2], ARGV[1]); 
    return 1;
end;
 
return nil;
```


**Redisson总结**
加锁流程核心就3步   
Step1：尝试获取锁，这一步是通过执行加锁Lua脚本来做；   
Step2：若第一步未获取到锁，则去订阅解锁消息，当获取锁到剩余过期时间后，调用信号量方法阻塞住，直到被唤醒或等待超时   
Step3：一旦持有锁的线程释放了锁，就会广播解锁消息。于是，第二步中的解锁消息的监听器会释放信号量，获取锁被阻塞的那些线程就会被唤醒，并重新尝试获取锁。


解锁流程相对比较简单，完全就是执行解锁Lua脚本，无额外的代码逻辑
#### 数据库和缓存的同步问题

##### (1)先更新数据库，再更新缓存
这套方案，大家是普遍反对的。为什么呢？有如下两点原因。
- **原因一（线程安全角度）**

同时有请求A和请求B进行更新操作，那么会出现

- 线程A更新了数据库
- 线程B更新了数据库
- 线程B更新了缓存
- 线程A更新了缓存

这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。

- **原因二（业务场景角度）**

有如下两点：

- 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
- 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。

##### (2)先删缓存，再更新数据库

该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

- 请求A进行写操作，删除缓存
- 请求B查询发现缓存不存在
- 请求B去数据库查询得到旧值
- 请求B将旧值写入缓存
- 请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

那么，如何解决呢？采用延时双删策略

伪代码如下

```java
public void write(String key,Object data){

        redis.delKey(key);

        db.updateData(data);

        Thread.sleep(1000);

        redis.delKey(key);
    }
```

转化为中文描述就是

- 先淘汰缓存
- 再写数据库（这两步和原来一样）
- 休眠1秒，再次淘汰缓存

这么做，可以将1秒内所造成的缓存脏数据，再次删除。

**那么，这个1秒怎么确定的，具体该休眠多久呢？**

针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

**如果你用了mysql的读写分离架构怎么办？**

ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。

- 请求A进行写操作，删除缓存
- 请求A将数据写入数据库了，
- 请求B查询缓存发现，缓存没有值
- 请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
- 请求B将旧值写入缓存
- 数据库完成主从同步，从库变为新值

上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

**采用这种同步淘汰策略，吞吐量降低怎么办？**

ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

##### (3)先更新数据库，再删缓存

**存在的问题：**
**在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值**。

有两种方法：

- 重试机制。
- 订阅 MySQL binlog，再操作缓存。

##### 重试机制

我们可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

- 如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
- 如果**删除缓存成功**，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。

举个例子，来说明重试机制的过程。

  

![](https://pic4.zhimg.com/80/v2-0ea25ee94f53d830b541e2f5e62d175b_1440w.webp)



##### 订阅 MySQL binlog，再操作缓存

「**先更新数据库，再删缓存**」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。

于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。

Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

下图是 Canal 的工作原理：

  ![[Pasted image 20230820232254.png]]

![](https://pic2.zhimg.com/80/v2-c4b3b944beff75fb34ae2e7b167e8f99_1440w.webp)

  

所以，**如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。**



#### 一个字符串类型的值能存储最大容量是多少？

- 答： 512M

#### Redis 的持久化机制是什么？各自的优缺点？

Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:

**RDB：是Redis DataBase缩写快照**

- RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。

![](https://ask.qcloudimg.com/http-save/7948575/0j5pebl80o.png)

**优点：**

1. 只有一个文件 dump.rdb，方便持久化。
2. 容灾性好，一个文件可以保存到安全的磁盘。
3. 性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单 独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能
4. 相对于数据集大时，比 AOF 的启动效率更高。

**缺点：**

1. [数据安全](https://cloud.tencent.com/solution/data_protection?from_column=20065&from=20065)性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数 据丢失。所以这种方式更适合数据要求不严谨的时候)
2. AOF（Append-only fifile)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式 完全持久化存储)保存为 aof 文件。

**AOF：持久化：**

- AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件
- 中，当重启Redis会重新将持久化的日志中文件恢复数据。当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复

![](https://ask.qcloudimg.com/http-save/7948575/s84hcc7nl.png)

**优点：**

1. 数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录 到 aof 文件中一次。
2. 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一 致性问题。
3. AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flflushall）)

**缺点：**

1. AOF 文件比 RDB 文件大，且恢复速度慢。
2. 数据集大的时候，比 rdb 启动效率低。

**俩种持久化的优缺点是什么？**

- AOF文件比RDB更新频率高，优先使用AOF还原数据。
- AOF比RDB更安全也更大
- RDB性能比AOF好
- 如果两个都配了优先加载AOF


#### redis写AOF日志时，会对主进程有影响吗？
在Redis中，AOF（Append-Only File）日志是一种持久化方式，用于记录写操作命令，以便在Redis重启时恢复数据。当Redis执行写操作时，它会将相应的命令追加到AOF日志中。这个过程本身会带来一些性能开销，但通常不会对Redis主进程产生显著影响。

在正常情况下，Redis主进程在执行写操作并将命令追加到AOF日志时，这些操作是在后台异步完成的。这意味着主进程不会因为写AOF日志而被阻塞，从而能够继续处理其他请求。

然而，在一些特殊情况下，AOF日志的写入可能会对主进程产生某些影响：

1. **AOF日志文件过大**：如果AOF日志文件变得非常大，Redis会触发**AOF重写**（AOF Rewrite）过程，这会导致CPU和磁盘的较高使用率，可能会在一定程度上影响主进程的性能。
    
2. **AOF同步选项设置**：AOF日志的同步选项（sync option）配置会影响主进程的性能。如果同步选项设置为"always"，每个写操作都会同步刷新AOF日志到磁盘，可能会引起主进程的性能下降。"always"选项提供最高的数据安全性，但代价是性能较低。较少的同步频率（如"everysec"或"no"）会提高性能，但数据可能会有一定程度的风险。
    

总的来说，正常情况下，AOF日志的写入不会显著影响Redis主进程的性能。但在配置AOF持久化时，需要根据业务需求、硬件性能和数据安全性需求来选择合适的配置选项，以平衡性能和数据的可靠性。


#### AOF重写（AOF Rewrite）是什么
AOF重写（AOF Rewrite）是Redis中一种用于优化AOF（Append-Only File）持久化文件的机制。AOF持久化是将写操作追加到AOF文件中，以记录数据库状态的持久化方式。随着时间的推移，AOF文件可能会变得非常大，影响性能和磁盘空间的利用。AOF重写的目的就是压缩和优化AOF文件，从而减小文件体积，提高性能。

AOF重写是在后台进行的操作，它的原理是基于数据库的状态。在执行AOF重写时，Redis会生成一个新的AOF文件，该文件只包含创建数据库的初始状态以及重新执行操作生成的命令，而不包含过期的或不再需要的命令。这样，通过将实际执行的操作记录为命令，可以生成一个相对较小且完整的AOF文件。

AOF重写的主要优势包括：

1. **压缩文件大小**：AOF重写能够显著减小AOF文件的体积，节省磁盘空间。
    
2. **提高性能**：较小的AOF文件意味着更少的磁盘I/O操作，可以提高读写性能。
    
3. **清除不再需要的命令**：随着时间的推移，AOF文件可能会包含大量已经过期或不再需要的命令，AOF重写可以清除这些命令，使文件更加精简。
    

要执行AOF重写，可以通过发送BGREWRITEAOF命令或配置auto-aof-rewrite-percentage和auto-aof-rewrite-min-size选项来触发。Redis会在后台生成新的AOF文件，并在生成完毕后进行替换，从而完成重写操作。需要注意的是，AOF重写可能会引起一定的CPU和磁盘I/O负载，因此需要在合适的时机执行，以避免对正常的数据库操作产生影响。


#### AOF重写时，如何保证一致？
在Redis进行AOF重写的过程中，为了保证数据一致性，需要采取一些特定的机制和步骤，以确保主进程在修改已经存在的key-value时，能够正确地进行同步。

具体来说，在AOF重写过程中，需要注意以下几个方面来保证一致性：

1. **AOF重写缓冲区**：Redis会使用一个缓冲区来暂存正在进行AOF重写的过程中发生的写操作。这个缓冲区会在AOF重写完成后进行刷写，以避免中途干扰正在执行的AOF重写操作。这样，已经存在的key-value的修改会被正确地记录到AOF重写缓冲区中。
    
2. **AOF重写期间的写操作**：在AOF重写期间，主进程仍然会接受并处理来自客户端的写操作请求。这些写操作会同时记录到AOF文件和AOF重写缓冲区中，以确保主进程和AOF重写进程之间的数据同步。
    
3. **AOF重写完成后的刷写**：当AOF重写完成后，Redis会将AOF重写缓冲区的内容一次性写入新的AOF文件中。这个过程会在瞬时进行，以确保已经存在的key-value的修改也被记录到新的AOF文件中。
    

总的来说，Redis在AOF重写过程中采取了一系列的机制，保证了主进程在修改已经存在的key-value时的一致性。这些机制确保了AOF重写的结果与主进程的写操作保持同步，从而维护了数据的一致性。


#### Redis单线程读写速度达到10万次/秒，Redis为什么这么快：

- Redis完全基于内存，持久化操作都是fork子进程和利用Linux缓存业技术实现的，不影响Redis性能。
    
- 单线程操作并不是坏事，单线程避免了频繁的上下文切换和频繁的创建和销毁线程
    
- 合理的数据结构
    
- Redis 使用了非阻塞的 I/O 多路复用机制来实现高性能的网络通信。这种机制使得 Redis 能够同时处理多个连接，而不会因为一个连接的阻塞 I/O 操作而影响其他连接的处理。以下是 Redis 使用的非阻塞 I/O 多路复用的一般工作流程：

#### Redis的过期删除策略：

1. 定期删除：Redis启用一个监视器定时检查所有的key，判断是否过期，如果过期就删除。缺点：非常消耗CPU资源，并且在还没有检查到已过期的key时，该key仍然可以使用。
    
2. 惰性删除：在使用key时再检查其是否过期。缺点：如果这个key一直未使用，则会占据内存空间。
    
3. 二者互补来完成过期删除的校验。定时删除只抽检一小部分的key，而惰性删除会检查剩余部分的key


#### Redis内存淘汰机制

当内存不够用时，内存淘汰机制就会上场。

从设置了过期时间的数据集中：

1. volatile-lru：挑选最近最少使用的key进行淘汰。
2. volatile-ttl：挑选将要淘汰的数据
3. volatile-random：随机挑选淘汰
4. allkeys-lru：在所有键当中，删除最近最少使用的key（常用）
5. allkeys-random：在所有键当中，删除最近最少使用的key
6. no-eviction:永不淘汰，当插入数据时直接报错。（默认）

4.0版本后新增：

1. volatile-lfu:从设置了过期时间的数据集中：挑选所有当中最不尝试用的
    
2. allkeys-lfu:从所有key当中挑选所有当中最不尝试用的



#### 缓存穿透：

查询的对象在数据库和Redis中都不存在

解决方法：缓存空对象，布隆过滤器，拉黑IP地址，进行参数校验


#### 缓存雪崩：

同一时间大量缓存同时失效

解决方法：给不同的key的ttl设置为随机值，或把热点key放在不同的Redis集群里来提高可用性。

#### 缓存击穿：

指一个高访问量的key突然失效。

1. 互斥锁，利用Redis的setNx方法，其余线程在重建缓存时休眠
    
2. 逻辑过期方案：在缓存字段中加入过期时间字段，查询时判断是否过期，如果过期，尝试获取互斥锁，若成功就更新，若失败就返回过期数据。
    
3. 设置永不过期

#### Redis 的主从同步机制
- 答：Redis 可以使用主从同步，从从同步。第一次同步时，主节点做一次 bgsave， 并同时将后续修改操作记录到内存 buffffer， 待完成后将 rdb 文件全量同步到复制节点， 复制节点接受完成后将 rdb 镜像加载到内存。加载完成后， 再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。

#### redis 的pipeline是什么

在 Redis 中，Pipeline 是一种用于批量执行多个命令的机制，它可以显著提高客户端与 Redis 服务器之间的通信效率，从而在某些情况下可以实现更高的吞吐量和更低的延迟。

通常情况下，当客户端向 Redis 发送命令时，客户端需要等待 Redis 执行完这个命令并返回结果，然后才能继续发送下一个命令。这会在一定程度上增加了网络通信的延迟，尤其是当需要执行多个命令时。

使用 Pipeline 机制，客户端可以将多个命令一次性发送到 Redis，而不需要等待每个命令的返回结果。Redis 会将这些命令按顺序执行，并将执行结果按顺序返回给客户端。这样，客户端可以在一次通信中发送多个命令，从而减少了网络通信的开销，提高了执行多个命令的效率。

使用 Pipeline 的一般步骤如下：

1. 客户端将多个命令按顺序发送给 Redis，而不需要等待每个命令的返回结果。
    
2. Redis 接收到这些命令后，按顺序执行它们。
    
3. Redis 将每个命令的执行结果按顺序返回给客户端。
    

Pipeline 不仅适用于读操作，也适用于写操作。对于某些操作，如读取多个键的值或批量设置多个键的值，Pipeline 可以显著减少通信次数，提高效率。

需要注意的是，Pipeline 并不能减少单个命令的执行时间，它主要的优势在于减少通信开销。但是，在需要执行多个命令的场景中，Pipeline 可以带来明显的性能提升。


#### redis的网络通信协议是什么
  
Redis 使用一种基于文本协议的网络通信协议，被称为 "Redis Protocol" 或 "RESP"（Redis Serialization Protocol）。这个协议设计得非常简单，易于实现，同时也具备一定的可读性，使得 Redis 客户端和服务器之间能够进行高效的通信。

RESP 支持多种数据类型的序列化和反序列化，包括字符串、整数、错误消息、数组等。RESP 的设计目标是既能够有效地传输数据，又能够在不同编程语言和平台之间进行互操作。

RESP 数据的序列化方式主要有以下几种：

1. **字符串和错误消息**：字符串和错误消息以 "$" 开头，后跟字符串的长度（以字节数表示），然后是换行符，接着是实际的字符串内容，最后是换行符。例如：`"$5\r\nhello\r\n"` 表示一个长度为 5 的字符串 "hello"。
    
2. **整数**：整数以 ":" 开头，后跟实际的整数值，然后是换行符。例如：`":42\r\n"` 表示整数值 42。
    
3. **数组**：数组以 "\*" 开头，后跟数组中元素的数量，然后是换行符，接着是数组中的每个元素，每个元素按 RESP 协议进行序列化，最后是换行符。例如：`"*3\r\n$3\r\nfoo\r\n$3\r\nbar\r\n$3\r\nbaz\r\n"` 表示一个包含三个字符串元素的数组：["foo", "bar", "baz"]。
    
4. **简单字符串**：简单字符串以 "+" 开头，后跟实际的字符串内容，然后是换行符。例如：`"+OK\r\n"` 表示一个简单字符串 "OK"。
    
5. **批量字符串**：批量字符串以 "$" 开头，后跟字符串的长度（以字节数表示），然后是换行符，接着是实际的字符串内容，最后是换行符。但是，当字符串为特殊值 "null" 时，也可以使用 "$-1\r\n" 表示。这对于表示空值非常有用。
    

这种简单的文本协议使得 Redis 的客户端和服务器之间能够进行有效的通信，并且由于其可读性，也方便了开发人员进行调试和开发。不同编程语言的 Redis 客户端库通常会负责处理 RESP 的序列化和反序列化，使得开发者在使用 Redis 时不需要直接操作 RESP 协议的细节。

#### Redis集群
Redis 集群是用于横向扩展 Redis 数据库的解决方案，它允许将数据分布在多个节点上，从而提供更高的性能、容错性和可用性。Redis 集群的设计目标是实现水平扩展，以处理大规模的数据和请求负载。

以下是 Redis 集群的一些关键概念和特性：

1. **节点拓扑结构**：Redis 集群由多个节点组成，这些节点可以分布在不同的物理机器或虚拟机上。每个节点都是一个独立的 Redis 实例。
    
2. **数据分片**：集群将数据分片存储在多个节点上。每个节点负责管理其中的一部分数据，通过哈希算法将数据映射到不同的节点。
    
3. **主从复制**：每个节点可以拥有多个从节点，用于数据备份和读取负载均衡。主节点负责处理写操作，从节点负责复制主节点的数据并处理读操作。
    
4. **故障转移**：集群支持节点的自动故障检测和转移。当主节点出现故障时，集群会自动将一个从节点升级为新的主节点，以保证服务的可用性。
    
5. **节点间通信**：集群节点之间使用一个专用的二进制协议进行通信，该协议负责数据同步、故障检测、故障转移等。
    
6. **握手阶段**：在启动时，节点会通过握手阶段来进行节点的自动发现和加入集群。集群的握手机制可以自动处理节点的加入和移除。
    
7. **配置文件**：集群配置文件描述了集群的拓扑结构、主从关系以及其他相关设置。
    
8. **客户端分区**：客户端可以通过一致性哈希等方式将数据请求发送到正确的节点上，从而实现分布式的数据访问。
    
9. **主从复制延迟**：由于主从复制的存在，可能会导致数据的略微延迟，但是 Redis 集群通常以数据的高可用性和分布式能力为主要目标。
    
10. **自动重新平衡**：当添加或删除节点时，集群会自动重新平衡数据，以确保数据在各节点之间均匀分布。


#### Redis哨兵Sentinel

Redis Sentinel（哨兵）是一种用于监控和管理 Redis 高可用性的解决方案。它可以自动检测 Redis 主节点和从节点的状态，以及在主节点故障时自动切换到一个可用的从节点，从而实现 Redis 的故障转移和自动恢复。

以下是 Redis Sentinel 的一些关键功能和作用：

1. **故障检测**：哨兵定期监控 Redis 主节点和从节点的状态。如果一个节点不可达，哨兵会检测到并标记该节点为不可用。
    
2. **故障转移**：当主节点出现故障时，哨兵会自动选举一个从节点升级为新的主节点，从而实现故障转移。这能够使得系统在主节点故障时仍然保持可用。
    
3. **自动恢复**：一旦原主节点恢复，哨兵也会自动将其重新加入集群作为从节点，并保证数据同步。
    
4. **监控和通知**：哨兵可以配置在节点状态变化时发送通知，如故障转移发生时发送警报通知，帮助管理员及时处理问题。
    
5. **配置更新**：哨兵允许动态更新 Redis 配置，如修改密码、修改节点 IP 地址等，而不需要停止整个集群。
    
6. **节点发现**：客户端可以通过连接到哨兵来获取 Redis 主节点和从节点的信息，从而动态适应节点变化。
    
7. **多数据中心支持**：哨兵支持多个 Redis 集群，以及跨多个数据中心的配置。
    

使用 Redis Sentinel，您可以实现 Redis 高可用性架构，确保 Redis 服务在主节点故障时能够自动切换到备用节点，从而减少系统的停机时间。哨兵的工作方式是通过集群的 Quorum（法定人数）机制来进行决策，确保只有足够多的哨兵达成一致，才会进行故障转移，防止误判。

需要注意的是，哨兵本身也需要被部署在高可用的架构中，以确保它不会成为单点故障。通常，建议至少部署三个哨兵来提供容错性。Redis Sentinel 并不是用来替代 Redis 集群的，而是作为一种轻量级的高可用性解决方案，适用于小到中等规模的 Redis 部署。

#### 所以 哨兵是一个节点吗

是的，Redis Sentinel（哨兵）本身也是一个独立的节点。哨兵节点是一个专门负责监控和管理 Redis 高可用性的进程，它与普通的 Redis 节点（主节点、从节点）不同，但也需要被部署在一个可靠的环境中，以确保不会成为单点故障。

一个完整的 Redis Sentinel 部署通常由多个哨兵节点组成，这些哨兵节点一起协同工作，监控 Redis 集群的状态，并在主节点故障时执行故障转移操作。哨兵节点之间通过消息传递来共享状态信息，确保集群的状态一致性。

在一个哨兵部署中，一般至少需要部署三个哨兵节点，以保证容错性。哨兵节点之间会通过选举机制来决定谁负责监控主节点的状态，以及在主节点故障时如何进行故障转移。当主节点出现故障时，被选举为 leader 的哨兵节点会协调其他哨兵节点，执行故障转移操作，将一个从节点升级为新的主节点，从而实现高可用性。

***要注意的是，哨兵节点本身不存储数据，它只是负责监控和管理 Redis 集群的状态。***
哨兵节点会定期与 Redis 节点进行通信，以检测节点的健康状态。如果主节点出现故障或不可达，哨兵节点会协调执行故障转移，并将一个从节点升级为新的主节点，从而保障服务的可用性。



#### Redis 如何保证原子性？
答案很简单，因为 Redis 是单线程的，所以 Redis 提供的 API 也是原子操作。

但我们业务中常常有先 get 后 set 的业务常见，在并发下会导致数据不一致的情况。

如何解决

1）使用 incr、decr、setnx 等原子操作；

2）客户端加锁；

3）使用 Lua 脚本实现 CAS 操作。

#### lua脚本如何实现原子性
Redis本身又是**单线程执行**lua脚本，保证了lua脚本在处理逻辑过程中**不会被任意其它请求打断**。

#### 有序集合 Zset 的底层实现？
zset 是 Redis 中一个非常重要的数据结构，其底层是基于跳表（skip list） 实现的。


ZSET的底层实现通常由两个数据结构组成：跳跃表（Skip List）和哈希表（Hash Table）。

1. **跳跃表（Skip List）**：跳跃表是一种有序数据结构，类似于链表，但通过添加多级索引节点来加速查找操作。跳跃表中的每个节点都包含一个成员和对应的分数。Redis的ZSET将所有成员和对应分数都存储在跳跃表中，以实现有序性。跳跃表的查询操作的平均时间复杂度为O(log n)，使得ZSET支持高效的查找和范围操作。ZSET（有序集合）的跳跃表（Skip List）是按照成员的分数（score）进行排序的。
    
2. **哈希表（Hash Table）**：为了支持高效的插入和删除操作，Redis在ZSET的底层也使用了哈希表。哈希表中的每个键都与一个跳跃表节点关联，该键是成员，值是分数。这样，当插入或删除成员时，可以在O(1)的时间内定位到对应的节点，并对跳跃表进行相应的操作。



跳表是一种随机化的数据结构，基于并联的链表，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。实现简单，插入、删除、查找的复杂度均为 O(logN)。简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供 O(logN) 的时间复杂度。

跳表为了避免每次插入或删除带来的额外操作，不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数（level）。而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。



